{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexandrepoupeau/Documents/work/code/halfcircle-clf/.venv/lib/python3.11/site-packages/torchvision/transforms/v2/_deprecated.py:42: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.Output is equivalent up to float precision.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexandrepoupeau/Documents/work/code/halfcircle-clf/.venv/lib/python3.11/site-packages/torchvision/transforms/v2/_deprecated.py:42: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.Output is equivalent up to float precision.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from datetime import datetime\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import lightning as pl\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchmetrics.classification import Accuracy, AUROC, F1Score\n",
    "\n",
    "sys.path.append('..')\n",
    "\n",
    "from src.data.generate import generate_half_circle_image\n",
    "from src.data.utils import get_image_paths\n",
    "from src.data.dataset import HalfCircleBinaryClfDataset\n",
    "from src.data.transforms import TRAIN_TRANSFORMS, TEST_TRANSFORMS\n",
    "from src.modeling.model import HCCLF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='mps')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('mps' if torch.mps.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_filepaths = get_image_paths(directory=\"/Users/alexandrepoupeau/Documents/work/code/halfcircle-clf/data/\")\n",
    "train_images_filepaths, test_images_filepaths = train_test_split(images_filepaths, test_size=0.2)\n",
    "train_images_filepaths, val_images_filepaths = train_test_split(train_images_filepaths, test_size=0.2)\n",
    "\n",
    "train_ds = HalfCircleBinaryClfDataset(images_filepaths=train_images_filepaths, transform=TRAIN_TRANSFORMS)\n",
    "val_ds = HalfCircleBinaryClfDataset(images_filepaths=val_images_filepaths, transform=TEST_TRANSFORMS)\n",
    "test_ds = HalfCircleBinaryClfDataset(images_filepaths=test_images_filepaths, transform=TEST_TRANSFORMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_ds, batch_size=64, shuffle=False, num_workers=4, persistent_workers=True, prefetch_factor=64)\n",
    "val_loader = DataLoader(val_ds, batch_size=64, shuffle=False, num_workers=4, persistent_workers=True)\n",
    "test_loader = DataLoader(test_ds, batch_size=64, shuffle=False, num_workers=2, persistent_workers=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ds[0][0].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ds[6][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = HCCLF(lr=1e-3).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = model.configure_optimizers()\n",
    "loss_fn = torch.nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(epoch_index, tb_writer):\n",
    "    threshold = 0.5\n",
    "    running_loss = 0.\n",
    "    running_auroc = 0.\n",
    "    running_accuracy = 0.\n",
    "    running_f1 = 0.\n",
    "    last_loss = 0.\n",
    "    step_logs = 100\n",
    "\n",
    "    # Here, we use enumerate(training_loader) instead of\n",
    "    # iter(training_loader) so that we can track the batch\n",
    "    # index and do some intra-epoch reporting\n",
    "    for i, data in enumerate(train_loader):\n",
    "        # Every data instance is an input + label pair\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.unsqueeze(1).to(torch.float32).to(device)\n",
    "\n",
    "        # Zero your gradients for every batch!\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Make predictions for this batch\n",
    "        outputs = model(inputs)\n",
    "        preds = (outputs >= threshold).float()\n",
    "\n",
    "        # Compute the loss and its gradients\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "\n",
    "        # Adjust learning weights\n",
    "        optimizer.step()\n",
    "\n",
    "        # Gather data and report\n",
    "        running_loss += loss.item()\n",
    "        auroc_value = AUROC(\"binary\").to(device)(outputs, labels)\n",
    "        running_auroc += auroc_value\n",
    "        accuracy_value = Accuracy(\"binary\").to(device)(preds, labels)\n",
    "        running_accuracy += accuracy_value\n",
    "        f1_value = F1Score(\"binary\").to(device)(preds, labels)\n",
    "        running_f1 += f1_value\n",
    "\n",
    "        if i % step_logs == step_logs - 1:\n",
    "            last_loss = running_loss / step_logs # loss per batch\n",
    "            last_accuracy = running_accuracy / step_logs\n",
    "            last_f1 = running_f1 / step_logs\n",
    "            last_auroc = running_auroc / step_logs\n",
    "\n",
    "            print('  batch {} loss: {} acc: {} f1: {} auroc: {}'.format(i + 1, last_loss, last_accuracy, last_f1, last_auroc))\n",
    "            tb_x = epoch_index * len(train_loader) + i + 1\n",
    "            tb_writer.add_scalar('Loss/train', last_loss, tb_x)\n",
    "\n",
    "            running_loss = 0.\n",
    "            running_accuracy = 0.\n",
    "            running_f1 = 0.\n",
    "            running_auroc = 0.\n",
    "\n",
    "    return last_loss, last_accuracy, last_f1, last_auroc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexandrepoupeau/Documents/work/code/halfcircle-clf/.venv/lib/python3.11/site-packages/torchvision/transforms/v2/_deprecated.py:42: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.Output is equivalent up to float precision.\n",
      "  warnings.warn(\n",
      "/Users/alexandrepoupeau/Documents/work/code/halfcircle-clf/.venv/lib/python3.11/site-packages/torchvision/transforms/v2/_deprecated.py:42: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.Output is equivalent up to float precision.\n",
      "  warnings.warn(\n",
      "/Users/alexandrepoupeau/Documents/work/code/halfcircle-clf/.venv/lib/python3.11/site-packages/torchvision/transforms/v2/_deprecated.py:42: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.Output is equivalent up to float precision.\n",
      "  warnings.warn(\n",
      "/Users/alexandrepoupeau/Documents/work/code/halfcircle-clf/.venv/lib/python3.11/site-packages/torchvision/transforms/v2/_deprecated.py:42: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.Output is equivalent up to float precision.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  batch 100 loss: 0.4777050167694688 acc: 0.7626562714576721 f1: 0.5982999205589294 auroc: 0.8762351274490356\n",
      "  batch 200 loss: 0.11137648088857531 acc: 0.9626562595367432 f1: 0.9585438370704651 auroc: 0.9903776049613953\n",
      "  batch 300 loss: 0.07534187356010079 acc: 0.9748437404632568 f1: 0.9718748331069946 auroc: 0.9939463138580322\n",
      "  batch 400 loss: 0.06219064167700708 acc: 0.9789062738418579 f1: 0.9759185314178467 auroc: 0.9964492917060852\n",
      "LOSS train 0.06219064167700708 valid 0.027745738625526428\n",
      "ACC train 0.9789062738418579 valid 0.9935024976730347\n",
      "F1SCORE train 0.9759185314178467 valid 0.9925121068954468\n",
      "AUROC train 0.9964492917060852 valid 0.999951183795929\n",
      "EPOCH 2:\n",
      "  batch 100 loss: 0.049636640921235084 acc: 0.983593761920929 f1: 0.9820197224617004 auroc: 0.9979079365730286\n",
      "  batch 200 loss: 0.05258568457560614 acc: 0.9820312261581421 f1: 0.9800695776939392 auroc: 0.9981149435043335\n",
      "  batch 300 loss: 0.030194255633978172 acc: 0.989062488079071 f1: 0.9878215789794922 auroc: 0.9994137287139893\n",
      "  batch 400 loss: 0.033427727790549394 acc: 0.9893749952316284 f1: 0.9881532788276672 auroc: 0.9985500574111938\n",
      "LOSS train 0.033427727790549394 valid 0.008279357105493546\n",
      "ACC train 0.9893749952316284 valid 0.9958230257034302\n",
      "F1SCORE train 0.9881532788276672 valid 0.9953158497810364\n",
      "AUROC train 0.9985500574111938 valid 1.0\n",
      "EPOCH 3:\n",
      "  batch 100 loss: 0.03770397307584062 acc: 0.98828125 f1: 0.9868670701980591 auroc: 0.9987660050392151\n",
      "  batch 200 loss: 0.029152640600514132 acc: 0.9896875023841858 f1: 0.9886521100997925 auroc: 0.9993882179260254\n",
      "  batch 300 loss: 0.033684045849367975 acc: 0.9892187714576721 f1: 0.9876177906990051 auroc: 0.9988696575164795\n",
      "  batch 400 loss: 0.027802976327948273 acc: 0.9909374713897705 f1: 0.9895356893539429 auroc: 0.9991687536239624\n",
      "LOSS train 0.027802976327948273 valid 0.005251158028841019\n",
      "ACC train 0.9909374713897705 valid 1.0\n",
      "F1SCORE train 0.9895356893539429 valid 1.0\n",
      "AUROC train 0.9991687536239624 valid 1.0\n",
      "EPOCH 4:\n",
      "  batch 100 loss: 0.02825472217577044 acc: 0.9915624856948853 f1: 0.9903311133384705 auroc: 0.9992727637290955\n",
      "  batch 200 loss: 0.041397597168106585 acc: 0.98828125 f1: 0.9864903092384338 auroc: 0.9985296726226807\n",
      "  batch 300 loss: 0.01990657443064265 acc: 0.9932812452316284 f1: 0.9922361969947815 auroc: 0.9994342923164368\n",
      "  batch 400 loss: 0.035905122924013995 acc: 0.9879687428474426 f1: 0.9863526821136475 auroc: 0.9989578723907471\n",
      "LOSS train 0.035905122924013995 valid 0.010996208526194096\n",
      "ACC train 0.9879687428474426 valid 0.9990717768669128\n",
      "F1SCORE train 0.9863526821136475 valid 0.9989711046218872\n",
      "AUROC train 0.9989578723907471 valid 0.9999805688858032\n",
      "EPOCH 5:\n",
      "  batch 100 loss: 0.02661283052584622 acc: 0.9921875 f1: 0.9913038611412048 auroc: 0.9993040561676025\n",
      "  batch 200 loss: 0.02454315389797557 acc: 0.9928125143051147 f1: 0.9916096329689026 auroc: 0.9990703463554382\n",
      "  batch 300 loss: 0.019757645954668987 acc: 0.9951562285423279 f1: 0.9946815371513367 auroc: 0.9994218349456787\n",
      "  batch 400 loss: 0.01748939434852218 acc: 0.9948437213897705 f1: 0.9942498803138733 auroc: 0.9996538758277893\n",
      "LOSS train 0.01748939434852218 valid 0.0016615939093753695\n",
      "ACC train 0.9948437213897705 valid 1.0\n",
      "F1SCORE train 0.9942498803138733 valid 1.0\n",
      "AUROC train 0.9996538758277893 valid 1.0\n"
     ]
    }
   ],
   "source": [
    "# Initializing in a separate cell so we can easily add more epochs to the same run\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "writer = SummaryWriter('../logs/runs/fashion_trainer_{}'.format(timestamp))\n",
    "epoch_number = 0\n",
    "\n",
    "EPOCHS = 5\n",
    "\n",
    "best_vloss = 1_000_000.\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print('EPOCH {}:'.format(epoch_number + 1))\n",
    "\n",
    "    # Make sure gradient tracking is on, and do a pass over the data\n",
    "    model.train(True)\n",
    "    avg_loss, avg_acc, avg_f1, avg_auroc = train_one_epoch(epoch_number, writer)\n",
    "\n",
    "\n",
    "    running_vloss = 0.0\n",
    "    running_vacc = 0.0\n",
    "    running_vf1 = 0.\n",
    "    running_vauroc = 0.\n",
    "\n",
    "    # Set the model to evaluation mode, disabling dropout and using population\n",
    "    # statistics for batch normalization.\n",
    "    model.eval()\n",
    "\n",
    "    # Disable gradient computation and reduce memory consumption.\n",
    "    with torch.no_grad():\n",
    "        for i, vdata in enumerate(val_loader):\n",
    "            vinputs, vlabels = vdata\n",
    "            vinputs = vinputs.to(device)\n",
    "            vlabels = vlabels.unsqueeze(1).to(torch.float32).to(device)\n",
    "            voutputs = model(vinputs)\n",
    "            vloss = loss_fn(voutputs, vlabels)\n",
    "            auroc_value = AUROC(\"binary\").to(device)(voutputs, vlabels)\n",
    "            running_vauroc += auroc_value\n",
    "            accuracy_value = Accuracy(\"binary\").to(device)(voutputs, vlabels)\n",
    "            running_vacc += accuracy_value\n",
    "            f1_value = F1Score(\"binary\").to(device)(voutputs, vlabels)\n",
    "            running_vf1 += f1_value\n",
    "            running_vloss += vloss\n",
    "\n",
    "    avg_vloss = running_vloss / (i + 1)\n",
    "    avg_vacc = running_vacc / (i + 1)\n",
    "    avg_vf1 = running_vf1 / (i + 1)\n",
    "    avg_vauroc = running_vauroc / (i + 1)\n",
    "    print('LOSS train {} valid {}'.format(avg_loss, avg_vloss))\n",
    "    print('ACC train {} valid {}'.format(avg_acc, avg_vacc))\n",
    "    print('F1SCORE train {} valid {}'.format(avg_f1, avg_vf1))\n",
    "    print('AUROC train {} valid {}'.format(avg_auroc, avg_vauroc))\n",
    "\n",
    "    # Log the running loss averaged per batch\n",
    "    # for both training and validation\n",
    "    writer.add_scalars('Training vs. Validation Loss',\n",
    "                    { 'Training' : avg_loss, 'Validation' : avg_vloss },\n",
    "                    epoch_number + 1)\n",
    "    writer.flush()\n",
    "\n",
    "    # Track best performance, and save the model's state\n",
    "    if avg_vloss < best_vloss:\n",
    "        best_vloss = avg_vloss\n",
    "        model_path = '../models/model_{}_{}.pt'.format(timestamp, epoch_number)\n",
    "        torch.save(model.state_dict(), model_path)\n",
    "\n",
    "    epoch_number += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS test 0.0015394717920571566\n",
      "ACC test 1.0\n",
      "F1SCORE test 1.0\n",
      "AUROC test 1.0\n"
     ]
    }
   ],
   "source": [
    "running_vloss = 0.0\n",
    "running_vacc = 0.0\n",
    "running_vf1 = 0.\n",
    "running_vauroc = 0.\n",
    "\n",
    "model.eval()\n",
    "\n",
    "# Disable gradient computation and reduce memory consumption.\n",
    "with torch.no_grad():\n",
    "    for i, vdata in enumerate(test_loader):\n",
    "        vinputs, vlabels = vdata\n",
    "        vinputs = vinputs.to(device)\n",
    "        vlabels = vlabels.unsqueeze(1).to(torch.float32).to(device)\n",
    "        voutputs = model(vinputs)\n",
    "        vloss = loss_fn(voutputs, vlabels)\n",
    "        auroc_value = AUROC(\"binary\").to(device)(voutputs, vlabels)\n",
    "        running_vauroc += auroc_value\n",
    "        accuracy_value = Accuracy(\"binary\").to(device)(voutputs, vlabels)\n",
    "        running_vacc += accuracy_value\n",
    "        f1_value = F1Score(\"binary\").to(device)(voutputs, vlabels)\n",
    "        running_vf1 += f1_value\n",
    "        running_vloss += vloss\n",
    "\n",
    "avg_vloss = running_vloss / (i + 1)\n",
    "avg_vacc = running_vacc / (i + 1)\n",
    "avg_vf1 = running_vf1 / (i + 1)\n",
    "avg_vauroc = running_vauroc / (i + 1)\n",
    "print('LOSS test {}'.format(avg_vloss))\n",
    "print('ACC test {}'.format(avg_vacc))\n",
    "print('F1SCORE test {}'.format(avg_vf1))\n",
    "print('AUROC test {}'.format(avg_vauroc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "halfcircle-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
