{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from datetime import datetime\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchmetrics.classification import Accuracy, AUROC, F1Score\n",
    "from torchvision.utils import make_grid\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "sys.path.append('..')\n",
    "\n",
    "from src.data.utils import get_image_paths\n",
    "from src.data.dataset import HalfCircleBinaryClfDataset\n",
    "from src.data.transforms import TRAIN_TRANSFORMS, TEST_TRANSFORMS\n",
    "from src.modeling.model import HCCLF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='mps')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('mps' if torch.mps.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_filepaths = get_image_paths(directory=\"/Users/alexandrepoupeau/Documents/work/code/perso/aitt-symbol-clf/data/\")\n",
    "train_images_filepaths, test_images_filepaths = train_test_split(images_filepaths, test_size=0.2)\n",
    "train_images_filepaths, val_images_filepaths = train_test_split(train_images_filepaths, test_size=0.2)\n",
    "\n",
    "train_ds = HalfCircleBinaryClfDataset(images_filepaths=train_images_filepaths, transform=TRAIN_TRANSFORMS)\n",
    "val_ds = HalfCircleBinaryClfDataset(images_filepaths=val_images_filepaths, transform=TEST_TRANSFORMS)\n",
    "test_ds = HalfCircleBinaryClfDataset(images_filepaths=test_images_filepaths, transform=TEST_TRANSFORMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_ds, batch_size=64, shuffle=False, num_workers=4, persistent_workers=True, prefetch_factor=64)\n",
    "val_loader = DataLoader(val_ds, batch_size=64, shuffle=False, num_workers=4, persistent_workers=True)\n",
    "test_loader = DataLoader(test_ds, batch_size=64, shuffle=False, num_workers=2, persistent_workers=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ds[0][0].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ds[7][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load pretrained model\n"
     ]
    }
   ],
   "source": [
    "load_pretrained = True\n",
    "pretrained_model_checkpoint_filepath = \"../models/keep/model_20250315_234944_47.pt\"\n",
    "\n",
    "if not load_pretrained:\n",
    "    model = HCCLF(lr=1e-4).to(device)\n",
    "else:\n",
    "    print(\"Load pretrained model\")\n",
    "    model = HCCLF(lr=1e-4).to(device)\n",
    "    model.load_state_dict(torch.load(pretrained_model_checkpoint_filepath))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = model.configure_optimizers()\n",
    "scheduler = ReduceLROnPlateau(optimizer, 'min')\n",
    "loss_fn = torch.nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(epoch_index, tb_writer):\n",
    "    threshold = 0.5\n",
    "    running_loss = 0.\n",
    "    running_auroc = 0.\n",
    "    running_accuracy = 0.\n",
    "    running_f1 = 0.\n",
    "    last_loss = 0.\n",
    "    step_logs = 100\n",
    "\n",
    "    # Here, we use enumerate(training_loader) instead of\n",
    "    # iter(training_loader) so that we can track the batch\n",
    "    # index and do some intra-epoch reporting\n",
    "    for i, data in enumerate(train_loader):\n",
    "        # Every data instance is an input + label pair\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.unsqueeze(1).to(torch.float32).to(device)\n",
    "\n",
    "        # Zero your gradients for every batch!\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Make predictions for this batch\n",
    "        outputs = model(inputs)\n",
    "        preds = (outputs >= threshold).float()\n",
    "\n",
    "        # Compute the loss and its gradients\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "\n",
    "        # Adjust learning weights\n",
    "        optimizer.step()\n",
    "\n",
    "        # Gather data and report\n",
    "        running_loss += loss.item()\n",
    "        auroc_value = AUROC(\"binary\").to(device)(outputs, labels)\n",
    "        running_auroc += auroc_value\n",
    "        accuracy_value = Accuracy(\"binary\").to(device)(preds, labels)\n",
    "        running_accuracy += accuracy_value\n",
    "        f1_value = F1Score(\"binary\").to(device)(preds, labels)\n",
    "        running_f1 += f1_value\n",
    "\n",
    "        if i % step_logs == step_logs - 1:\n",
    "            last_loss = running_loss / step_logs # loss per batch\n",
    "            last_accuracy = running_accuracy / step_logs\n",
    "            last_f1 = running_f1 / step_logs\n",
    "            last_auroc = running_auroc / step_logs\n",
    "\n",
    "            # print('  batch {} loss: {} acc: {} f1: {} auroc: {}'.format(i + 1, last_loss, last_accuracy, last_f1, last_auroc))\n",
    "            tb_x = epoch_index * len(train_loader) + i + 1\n",
    "            tb_writer.add_scalar('Loss/train', last_loss, tb_x)\n",
    "\n",
    "            running_loss = 0.\n",
    "            running_accuracy = 0.\n",
    "            running_f1 = 0.\n",
    "            running_auroc = 0.\n",
    "\n",
    "    return last_loss, last_accuracy, last_f1, last_auroc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexandrepoupeau/.pyenv/versions/3.11.10/envs/aitt-symb-venv/lib/python3.11/site-packages/torchvision/transforms/v2/_deprecated.py:42: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.Output is equivalent up to float precision.\n",
      "  warnings.warn(\n",
      "/Users/alexandrepoupeau/.pyenv/versions/3.11.10/envs/aitt-symb-venv/lib/python3.11/site-packages/torchvision/transforms/v2/_deprecated.py:42: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.Output is equivalent up to float precision.\n",
      "  warnings.warn(\n",
      "/Users/alexandrepoupeau/.pyenv/versions/3.11.10/envs/aitt-symb-venv/lib/python3.11/site-packages/torchvision/transforms/v2/_deprecated.py:42: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.Output is equivalent up to float precision.\n",
      "  warnings.warn(\n",
      "/Users/alexandrepoupeau/.pyenv/versions/3.11.10/envs/aitt-symb-venv/lib/python3.11/site-packages/torchvision/transforms/v2/_deprecated.py:42: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.Output is equivalent up to float precision.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1:\n",
      "EPOCH 2:\n",
      "EPOCH 3:\n",
      "EPOCH 4:\n",
      "EPOCH 5:\n"
     ]
    }
   ],
   "source": [
    "# Initializing in a separate cell so we can easily add more epochs to the same run\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "writer = SummaryWriter('../runs/hcclf_trainer_{}'.format(timestamp))\n",
    "\n",
    "dataiter = iter(train_loader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "grid = make_grid(images)\n",
    "writer.add_image('images', grid)\n",
    "\n",
    "# writer.add_graph(model=model, input_to_model=images)\n",
    "\n",
    "epoch_number = 0\n",
    "\n",
    "EPOCHS = 5\n",
    "\n",
    "best_vloss = 1e6\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print('EPOCH {}:'.format(epoch_number + 1))\n",
    "\n",
    "    # Make sure gradient tracking is on, and do a pass over the data\n",
    "    model.train(True)\n",
    "    avg_loss, avg_acc, avg_f1, avg_auroc = train_one_epoch(epoch_number, writer)\n",
    "\n",
    "    running_vloss = 0.0\n",
    "    running_vacc = 0.0\n",
    "    running_vf1 = 0.\n",
    "    running_vauroc = 0.\n",
    "\n",
    "    # Set the model to evaluation mode, disabling dropout and using population\n",
    "    # statistics for batch normalization.\n",
    "    model.eval()\n",
    "\n",
    "    # Disable gradient computation and reduce memory consumption.\n",
    "    with torch.no_grad():\n",
    "        for i, vdata in enumerate(val_loader):\n",
    "            vinputs, vlabels = vdata\n",
    "            vinputs = vinputs.to(device)\n",
    "            vlabels = vlabels.unsqueeze(1).to(torch.float32).to(device)\n",
    "            voutputs = model(vinputs)\n",
    "            vloss = loss_fn(voutputs, vlabels)\n",
    "            auroc_value = AUROC(\"binary\").to(device)(voutputs, vlabels)\n",
    "            running_vauroc += auroc_value\n",
    "            accuracy_value = Accuracy(\"binary\").to(device)(voutputs, vlabels)\n",
    "            running_vacc += accuracy_value\n",
    "            f1_value = F1Score(\"binary\").to(device)(voutputs, vlabels)\n",
    "            running_vf1 += f1_value\n",
    "            running_vloss += vloss\n",
    "\n",
    "    scheduler.step(vloss)\n",
    "\n",
    "    avg_vloss = running_vloss / (i + 1)\n",
    "    avg_vacc = running_vacc / (i + 1)\n",
    "    avg_vf1 = running_vf1 / (i + 1)\n",
    "    avg_vauroc = running_vauroc / (i + 1)\n",
    "    # print('LOSS train {} valid {}'.format(avg_loss, avg_vloss))\n",
    "    # print('ACC train {} valid {}'.format(avg_acc, avg_vacc))\n",
    "    # print('F1SCORE train {} valid {}'.format(avg_f1, avg_vf1))\n",
    "    # print('AUROC train {} valid {}'.format(avg_auroc, avg_vauroc))\n",
    "\n",
    "    # Log the running loss averaged per batch\n",
    "    # for both training and validation\n",
    "    writer.add_scalars('Loss/diff',\n",
    "                    { 'Training' : avg_loss, 'Validation' : avg_vloss },\n",
    "                    epoch_number + 1)\n",
    "    writer.add_scalars('Accuracy/diff',\n",
    "                    { 'Training' : avg_acc, 'Validation' : avg_vacc },\n",
    "                    epoch_number + 1)\n",
    "    writer.add_scalars('F1Score/diff',\n",
    "                    { 'Training' : avg_f1, 'Validation' : avg_vf1 },\n",
    "                    epoch_number + 1)\n",
    "    writer.add_scalars('AUROC/diff',\n",
    "                    { 'Training' : avg_auroc, 'Validation' : avg_vauroc },\n",
    "                    epoch_number + 1)\n",
    "    writer.flush()\n",
    "\n",
    "    # Track best performance, and save the model's state\n",
    "    if avg_vloss < best_vloss:\n",
    "        best_vloss = avg_vloss\n",
    "        model_path = '../models/model_{}_{}.pt'.format(timestamp, epoch_number)\n",
    "        torch.save(model.state_dict(), model_path)\n",
    "\n",
    "    epoch_number += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS test 0.008875399827957153\n",
      "ACC test 0.9986076951026917\n",
      "F1SCORE test 0.9967607259750366\n",
      "AUROC test 0.999913215637207\n"
     ]
    }
   ],
   "source": [
    "running_vloss = 0.0\n",
    "running_vacc = 0.0\n",
    "running_vf1 = 0.\n",
    "running_vauroc = 0.\n",
    "\n",
    "model.eval()\n",
    "\n",
    "# Disable gradient computation and reduce memory consumption.\n",
    "with torch.no_grad():\n",
    "    for i, vdata in enumerate(test_loader):\n",
    "        vinputs, vlabels = vdata\n",
    "        vinputs = vinputs.to(device)\n",
    "        vlabels = vlabels.unsqueeze(1).to(torch.float32).to(device)\n",
    "        voutputs = model(vinputs)\n",
    "        vloss = loss_fn(voutputs, vlabels)\n",
    "        auroc_value = AUROC(\"binary\").to(device)(voutputs, vlabels)\n",
    "        running_vauroc += auroc_value\n",
    "        accuracy_value = Accuracy(\"binary\").to(device)(voutputs, vlabels)\n",
    "        running_vacc += accuracy_value\n",
    "        f1_value = F1Score(\"binary\").to(device)(voutputs, vlabels)\n",
    "        running_vf1 += f1_value\n",
    "        running_vloss += vloss\n",
    "\n",
    "avg_vloss = running_vloss / (i + 1)\n",
    "avg_vacc = running_vacc / (i + 1)\n",
    "avg_vf1 = running_vf1 / (i + 1)\n",
    "avg_vauroc = running_vauroc / (i + 1)\n",
    "print('LOSS test {}'.format(avg_vloss))\n",
    "print('ACC test {}'.format(avg_vacc))\n",
    "print('F1SCORE test {}'.format(avg_vf1))\n",
    "print('AUROC test {}'.format(avg_vauroc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aitt-symb-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
